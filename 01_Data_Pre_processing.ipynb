{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288ff785",
   "metadata": {
    "id": "288ff785"
   },
   "source": [
    "<h1>Overview</h1>\n",
    "\n",
    "In this notebook, we will examine the used dataset which is a collection of scientific publications. Each entry consists of an ID, title, and the abstract section of the scientific publication or research paper. The abstracts are going to be fed to our model in order to obtain thier vector representations (embeddings).\n",
    "\n",
    "This notebook is going to do the following:\n",
    "1. <b>Data cleaning</b>: Remove nulls and non-English entries.\n",
    "2. <b>Encoding of abstracts</b>: Obtain the vector representation (encoding) of each abstract.\n",
    "3. <b>Keyword extraction</b>: Extract the most relevant keywords from each abstract.\n",
    "4. <b>Output</b>: Export the results to be used in the next stage.\n",
    "\n",
    "<b style=\"color:green;\">Don't worry, I will provide explanations for each step along the way..</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df9008",
   "metadata": {
    "id": "49df9008"
   },
   "source": [
    "<h1>Import libraries</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7561421c",
   "metadata": {
    "id": "7561421c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from langdetect import detect, DetectorFactory\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "tqdm.pandas() # Initialize tqdm for pandas (for the progress bar)\n",
    "DetectorFactory.seed = 0 # To have consistant results from langdetect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442bafe",
   "metadata": {
    "id": "2442bafe"
   },
   "source": [
    "<h1>Import data</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4ec9cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3a4ec9cb",
    "outputId": "6b3d4ef7-f6e9-4be7-fff1-fc8e21ea346a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_raw\",\n  \"rows\": 7548,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7548,\n        \"samples\": [\n          \"e423b3cd-bb6e-4243-8cfc-3ffb7535f521\",\n          \"0cf5df37-11a0-834f-837d-66c3c3308af2\",\n          \"edbdbbae-a3c2-ee4f-9b65-81c621d7db1c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6747,\n        \"samples\": [\n          \"Extracting Keywords from Publication Abstracts for an Automated Researcher Recommendation System\",\n          \"Molecular Dynamics Simulation of the Surface Pressure of Colloidal Monolayers\",\n          \"eHealth and Evidence-based IT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstractText\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1488,\n        \"samples\": [\n          \"Aerospace structures are designed to tight dimensional tolerances in order to ensure ease of fit during assembly. Geometrical deviations of the part \\u201cas built\\u201d from the nominal tooling inherently arising from the manufacturing process of carbon fiber reinforced plastics can pose a significant risk to production through unexpected delays and rework cost. Process analysis and modeling of relevant mechanisms inducing part distortion can be used to alleviate the risk. This book contributes a framework for guiding the analysis engineer in choosing appropriate modeling tools and the respective level of detail for the assessment of process induced deformations (PID) on a given use case.\",\n          \"Degradation of network performance during video transmission may lead to disturbing visual artifacts. Some packets might be lost, corrupted or delayed, making it impossible to properly decode the video data on time at the receiver. The quality of the error-concealment technique, as well as the spatial and temporal position of the artifacts have a large impact on the perceived quality after decoding. In this paper, we use the spatial scalability feature of Scalable Video Coding (SVC) for error-concealment. This enables the transmission of a lower resolution video with a higher robustness, for example using unequal error protection. Under the assumption that only the higher resolution video would be affected, we evaluated the visual impact of packet losses in a large scale subjective video quality experiment using the Absolute Category Rating method. The number of impairments, the duration, and the interval between impairments as well the quality of the encoded lower resolution video are varied in a systematic evaluation. This allows for analyzing the influence of each factor both independently and jointly.\",\n          \"Scalable Video Coding (SVC) provides a way to encapsulate several video layers with increasing quality and resolution in a single bitstream. Thus it is particularly adapted to address heterogeneous networks and a wide variety of decoding devices. In this paper, we evaluate the interest of SVC in a different context, which is error concealment after transmission on networks subject to packet loss. The encoded scalable video streams contain two layers with different spatial and temporal resolutions designed for mobile video communications with medium size and average to low bitrates. The main idea is to use the base layer to conceal errors in the higher layers if they are corrupted or lost. The base layer is first upscaled either spatially or temporally to reach the same resolution as the layer to conceal. Two error-concealment techniques using the base layer are then proposed for the MPEG-4 SVC standard, involving frame-level concealment and pixel-level concealment. These techniques are compared to the upscaled base layer as well as to a classical single-layer MPEG- 4 AVC/H.264 error-concealment technique. The comparison is carried out through a subjective experiment, in order to evaluate the Quality-of-Experience of the proposed techniques. We study several scenarios involving various bitrates and resolutions for the base layer of the SVC streams. The results show that SVC-based error concealment can provide significantly higher visual quality than single-layer-based techniques. Moreover, we demonstrate that the resolution and bitrate of the base layer have a strong impact on the perceived quality of the concealment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_raw"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-87fc97bd-4a7c-491d-a3cd-a466b1448d7d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstractText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000212c0-370f-df46-a901-1a8962645f6f</td>\n",
       "      <td>Measuring perceived depth in natural images an...</td>\n",
       "      <td>The perception of depth in images and video se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009bed2-bf63-1f43-977c-b7823fa0029d</td>\n",
       "      <td>Quasi-continuous High Pressure Preservation – ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00101882-6f36-a74b-bc93-231cd4d09a68</td>\n",
       "      <td>Refractive Microprisms with Improved Surface Q...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00130705-0760-d24e-81db-7bb32b537bf9</td>\n",
       "      <td>Gemeinsam Fotografien dokumentieren – Kollabor...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0020df72-aae3-ae41-b007-ce47fbaba7ca</td>\n",
       "      <td>Das \"Grundgesetz\" für die Leistungsbeschreibun...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87fc97bd-4a7c-491d-a3cd-a466b1448d7d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-87fc97bd-4a7c-491d-a3cd-a466b1448d7d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-87fc97bd-4a7c-491d-a3cd-a466b1448d7d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-bad184d2-d95c-41e8-bd5c-240e3b984a02\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bad184d2-d95c-41e8-bd5c-240e3b984a02')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-bad184d2-d95c-41e8-bd5c-240e3b984a02 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  000212c0-370f-df46-a901-1a8962645f6f   \n",
       "1  0009bed2-bf63-1f43-977c-b7823fa0029d   \n",
       "2  00101882-6f36-a74b-bc93-231cd4d09a68   \n",
       "3  00130705-0760-d24e-81db-7bb32b537bf9   \n",
       "4  0020df72-aae3-ae41-b007-ce47fbaba7ca   \n",
       "\n",
       "                                               title  \\\n",
       "0  Measuring perceived depth in natural images an...   \n",
       "1  Quasi-continuous High Pressure Preservation – ...   \n",
       "2  Refractive Microprisms with Improved Surface Q...   \n",
       "3  Gemeinsam Fotografien dokumentieren – Kollabor...   \n",
       "4  Das \"Grundgesetz\" für die Leistungsbeschreibun...   \n",
       "\n",
       "                                        abstractText  \n",
       "0  The perception of depth in images and video se...  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df_raw = pd.read_json(r'input/abstracts.json', encoding=\"utf8\")\n",
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ad40d",
   "metadata": {
    "id": "7f4ad40d"
   },
   "source": [
    "<h1>Clean data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a59954",
   "metadata": {
    "id": "68a59954"
   },
   "source": [
    "<h3 style=\"color:blue;\">Examine the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355e9f46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "355e9f46",
    "outputId": "7e74d920-a853-45fb-f838-3ea21b51f4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7548 entries, 0 to 7547\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            7548 non-null   object\n",
      " 1   title         7548 non-null   object\n",
      " 2   abstractText  1500 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 235.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at what we have\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f8ba8",
   "metadata": {
    "id": "644f8ba8"
   },
   "source": [
    "The above cell shows that we have 3 properties (id, title, and abstractText), however, we are only interested in the abstractText. The abstract serves as an ideal input for the model since it holds the summarized semantic content of the scientific research.\n",
    "\n",
    "We see that the dataset contains only 1500 non-null entries, therefore we will exclude null values in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a9bfb",
   "metadata": {
    "id": "a77a9bfb"
   },
   "source": [
    "<h3 style=\"color:blue;\">Remove NA</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae5f158",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "fae5f158",
    "outputId": "f29aec3f-ce2f-4e3c-9477-6ff4231d6eb7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_cleaned\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          \"b9b65530-86ad-a34f-b9b3-c573122e53ef\",\n          \"e7bd1a84-a90c-1943-8705-d1b2fee36138\",\n          \"42c57423-4d56-5d4c-9013-0462ae76087d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1487,\n        \"samples\": [\n          \"Analysis and Compensation of Process Induced Deformations in Composite Structures\",\n          \"A hybrid machine learning model for intrusion detection in VANET\",\n          \"Evaluation of MPEG4-SVC for QoE Protection in the Context of Transmission Errors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstractText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1488,\n        \"samples\": [\n          \"Aerospace structures are designed to tight dimensional tolerances in order to ensure ease of fit during assembly. Geometrical deviations of the part \\u201cas built\\u201d from the nominal tooling inherently arising from the manufacturing process of carbon fiber reinforced plastics can pose a significant risk to production through unexpected delays and rework cost. Process analysis and modeling of relevant mechanisms inducing part distortion can be used to alleviate the risk. This book contributes a framework for guiding the analysis engineer in choosing appropriate modeling tools and the respective level of detail for the assessment of process induced deformations (PID) on a given use case.\",\n          \"Degradation of network performance during video transmission may lead to disturbing visual artifacts. Some packets might be lost, corrupted or delayed, making it impossible to properly decode the video data on time at the receiver. The quality of the error-concealment technique, as well as the spatial and temporal position of the artifacts have a large impact on the perceived quality after decoding. In this paper, we use the spatial scalability feature of Scalable Video Coding (SVC) for error-concealment. This enables the transmission of a lower resolution video with a higher robustness, for example using unequal error protection. Under the assumption that only the higher resolution video would be affected, we evaluated the visual impact of packet losses in a large scale subjective video quality experiment using the Absolute Category Rating method. The number of impairments, the duration, and the interval between impairments as well the quality of the encoded lower resolution video are varied in a systematic evaluation. This allows for analyzing the influence of each factor both independently and jointly.\",\n          \"Scalable Video Coding (SVC) provides a way to encapsulate several video layers with increasing quality and resolution in a single bitstream. Thus it is particularly adapted to address heterogeneous networks and a wide variety of decoding devices. In this paper, we evaluate the interest of SVC in a different context, which is error concealment after transmission on networks subject to packet loss. The encoded scalable video streams contain two layers with different spatial and temporal resolutions designed for mobile video communications with medium size and average to low bitrates. The main idea is to use the base layer to conceal errors in the higher layers if they are corrupted or lost. The base layer is first upscaled either spatially or temporally to reach the same resolution as the layer to conceal. Two error-concealment techniques using the base layer are then proposed for the MPEG-4 SVC standard, involving frame-level concealment and pixel-level concealment. These techniques are compared to the upscaled base layer as well as to a classical single-layer MPEG- 4 AVC/H.264 error-concealment technique. The comparison is carried out through a subjective experiment, in order to evaluate the Quality-of-Experience of the proposed techniques. We study several scenarios involving various bitrates and resolutions for the base layer of the SVC streams. The results show that SVC-based error concealment can provide significantly higher visual quality than single-layer-based techniques. Moreover, we demonstrate that the resolution and bitrate of the base layer have a strong impact on the perceived quality of the concealment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_cleaned"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-4ec2d073-27d2-459c-a26b-b47b6d924988\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstractText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000212c0-370f-df46-a901-1a8962645f6f</td>\n",
       "      <td>Measuring perceived depth in natural images an...</td>\n",
       "      <td>The perception of depth in images and video se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00260961-8319-c84a-b84f-a83f557af45f</td>\n",
       "      <td>VNREAL: Virtual Network Resource Embedding Alg...</td>\n",
       "      <td>Network virtualization is recognized as an ena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00650278-d57c-874e-8fd3-355e26a35f21</td>\n",
       "      <td>Komplementärmedizin in der Onkologie – Evidenz...</td>\n",
       "      <td>Tumorpatienten sind im Verlauf ihrer Erkrankun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ec2d073-27d2-459c-a26b-b47b6d924988')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4ec2d073-27d2-459c-a26b-b47b6d924988 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4ec2d073-27d2-459c-a26b-b47b6d924988');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-dbcc6716-947a-4a54-8400-29828bf82600\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbcc6716-947a-4a54-8400-29828bf82600')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-dbcc6716-947a-4a54-8400-29828bf82600 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  000212c0-370f-df46-a901-1a8962645f6f   \n",
       "6  00260961-8319-c84a-b84f-a83f557af45f   \n",
       "8  00650278-d57c-874e-8fd3-355e26a35f21   \n",
       "\n",
       "                                               title  \\\n",
       "0  Measuring perceived depth in natural images an...   \n",
       "6  VNREAL: Virtual Network Resource Embedding Alg...   \n",
       "8  Komplementärmedizin in der Onkologie – Evidenz...   \n",
       "\n",
       "                                        abstractText  \n",
       "0  The perception of depth in images and video se...  \n",
       "6  Network virtualization is recognized as an ena...  \n",
       "8  Tumorpatienten sind im Verlauf ihrer Erkrankun...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude entries that don't have an abstract text\n",
    "df_cleaned = df_raw[~df_raw['abstractText'].isna()]\n",
    "\n",
    "# For testing purposes, uncomment the next line to limit the number of entries\n",
    "# df_cleaned = df_cleaned.head(10)\n",
    "\n",
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b1387",
   "metadata": {
    "id": "8d0b1387"
   },
   "source": [
    "<h3 style=\"color:blue;\">Remove non-English abstracts</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a47e87",
   "metadata": {
    "id": "14a47e87"
   },
   "source": [
    "You may have noticed some abstracts are written in German. We'll exclude any non-English entries since the models we're using are trained on corpus of English data. If you're considering including other languages, then multilingual models are suitable for that purpose. To detect the language of each abstract, we'll use langdetect package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4a72e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "bf4a72e9",
    "outputId": "47305aa8-05b2-4594-a8df-aa2f8d25aa92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:14<00:00, 105.78it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_cleaned\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          \"b9b65530-86ad-a34f-b9b3-c573122e53ef\",\n          \"e7bd1a84-a90c-1943-8705-d1b2fee36138\",\n          \"42c57423-4d56-5d4c-9013-0462ae76087d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1487,\n        \"samples\": [\n          \"Analysis and Compensation of Process Induced Deformations in Composite Structures\",\n          \"A hybrid machine learning model for intrusion detection in VANET\",\n          \"Evaluation of MPEG4-SVC for QoE Protection in the Context of Transmission Errors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstractText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1488,\n        \"samples\": [\n          \"Aerospace structures are designed to tight dimensional tolerances in order to ensure ease of fit during assembly. Geometrical deviations of the part \\u201cas built\\u201d from the nominal tooling inherently arising from the manufacturing process of carbon fiber reinforced plastics can pose a significant risk to production through unexpected delays and rework cost. Process analysis and modeling of relevant mechanisms inducing part distortion can be used to alleviate the risk. This book contributes a framework for guiding the analysis engineer in choosing appropriate modeling tools and the respective level of detail for the assessment of process induced deformations (PID) on a given use case.\",\n          \"Degradation of network performance during video transmission may lead to disturbing visual artifacts. Some packets might be lost, corrupted or delayed, making it impossible to properly decode the video data on time at the receiver. The quality of the error-concealment technique, as well as the spatial and temporal position of the artifacts have a large impact on the perceived quality after decoding. In this paper, we use the spatial scalability feature of Scalable Video Coding (SVC) for error-concealment. This enables the transmission of a lower resolution video with a higher robustness, for example using unequal error protection. Under the assumption that only the higher resolution video would be affected, we evaluated the visual impact of packet losses in a large scale subjective video quality experiment using the Absolute Category Rating method. The number of impairments, the duration, and the interval between impairments as well the quality of the encoded lower resolution video are varied in a systematic evaluation. This allows for analyzing the influence of each factor both independently and jointly.\",\n          \"Scalable Video Coding (SVC) provides a way to encapsulate several video layers with increasing quality and resolution in a single bitstream. Thus it is particularly adapted to address heterogeneous networks and a wide variety of decoding devices. In this paper, we evaluate the interest of SVC in a different context, which is error concealment after transmission on networks subject to packet loss. The encoded scalable video streams contain two layers with different spatial and temporal resolutions designed for mobile video communications with medium size and average to low bitrates. The main idea is to use the base layer to conceal errors in the higher layers if they are corrupted or lost. The base layer is first upscaled either spatially or temporally to reach the same resolution as the layer to conceal. Two error-concealment techniques using the base layer are then proposed for the MPEG-4 SVC standard, involving frame-level concealment and pixel-level concealment. These techniques are compared to the upscaled base layer as well as to a classical single-layer MPEG- 4 AVC/H.264 error-concealment technique. The comparison is carried out through a subjective experiment, in order to evaluate the Quality-of-Experience of the proposed techniques. We study several scenarios involving various bitrates and resolutions for the base layer of the SVC streams. The results show that SVC-based error concealment can provide significantly higher visual quality than single-layer-based techniques. Moreover, we demonstrate that the resolution and bitrate of the base layer have a strong impact on the perceived quality of the concealment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"de\",\n          \"sw\",\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_cleaned"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-503911e0-a92d-4174-9e73-b5fde529dcc5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000212c0-370f-df46-a901-1a8962645f6f</td>\n",
       "      <td>Measuring perceived depth in natural images an...</td>\n",
       "      <td>The perception of depth in images and video se...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00260961-8319-c84a-b84f-a83f557af45f</td>\n",
       "      <td>VNREAL: Virtual Network Resource Embedding Alg...</td>\n",
       "      <td>Network virtualization is recognized as an ena...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00650278-d57c-874e-8fd3-355e26a35f21</td>\n",
       "      <td>Komplementärmedizin in der Onkologie – Evidenz...</td>\n",
       "      <td>Tumorpatienten sind im Verlauf ihrer Erkrankun...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>006db203-8627-2f40-979e-5cd17aee5785</td>\n",
       "      <td>Kurzer Prozeß mit Ebenheit - Ebenheitsmessung ...</td>\n",
       "      <td>Evenness measurement on polished support plate...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00963793-ef84-b84c-9dd9-37f43546fdf9</td>\n",
       "      <td>Konkurrierende Partner, kooperierende Wettbewe...</td>\n",
       "      <td>Innovationsnetzwerke sind primär durch Koopera...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-503911e0-a92d-4174-9e73-b5fde529dcc5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-503911e0-a92d-4174-9e73-b5fde529dcc5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-503911e0-a92d-4174-9e73-b5fde529dcc5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9b06ed06-94ce-406a-bfb9-08339f07d56b\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b06ed06-94ce-406a-bfb9-08339f07d56b')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9b06ed06-94ce-406a-bfb9-08339f07d56b button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   000212c0-370f-df46-a901-1a8962645f6f   \n",
       "6   00260961-8319-c84a-b84f-a83f557af45f   \n",
       "8   00650278-d57c-874e-8fd3-355e26a35f21   \n",
       "10  006db203-8627-2f40-979e-5cd17aee5785   \n",
       "15  00963793-ef84-b84c-9dd9-37f43546fdf9   \n",
       "\n",
       "                                                title  \\\n",
       "0   Measuring perceived depth in natural images an...   \n",
       "6   VNREAL: Virtual Network Resource Embedding Alg...   \n",
       "8   Komplementärmedizin in der Onkologie – Evidenz...   \n",
       "10  Kurzer Prozeß mit Ebenheit - Ebenheitsmessung ...   \n",
       "15  Konkurrierende Partner, kooperierende Wettbewe...   \n",
       "\n",
       "                                         abstractText language  \n",
       "0   The perception of depth in images and video se...       en  \n",
       "6   Network virtualization is recognized as an ena...       en  \n",
       "8   Tumorpatienten sind im Verlauf ihrer Erkrankun...       de  \n",
       "10  Evenness measurement on polished support plate...       en  \n",
       "15  Innovationsnetzwerke sind primär durch Koopera...       de  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function that returns the language of a given text\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "# Apply the function to create a new column 'language'\n",
    "df_cleaned.loc[:, 'language'] = df_cleaned['abstractText'].progress_apply(detect_language)\n",
    "df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c203da61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "c203da61",
    "outputId": "cba45fd7-1cd5-4d4a-cfeb-f5d711996c1f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_cleaned[['language', 'id']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"de\",\n          \"sw\",\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 580,\n        \"min\": 1,\n        \"max\": 1330,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1330,\n          167,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-28ff941e-1bba-42e5-b977-55f353449de5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sw</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28ff941e-1bba-42e5-b977-55f353449de5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-28ff941e-1bba-42e5-b977-55f353449de5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-28ff941e-1bba-42e5-b977-55f353449de5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b773bc22-7a39-4d38-a7d1-300b7e198f23\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b773bc22-7a39-4d38-a7d1-300b7e198f23')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b773bc22-7a39-4d38-a7d1-300b7e198f23 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "            id\n",
       "language      \n",
       "en        1330\n",
       "de         167\n",
       "es           1\n",
       "fr           1\n",
       "sw           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the number of abstracts per language\n",
    "df_cleaned[['language', 'id']].groupby(['language']).count().sort_values(by='id', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8273bf29",
   "metadata": {
    "id": "8273bf29"
   },
   "outputs": [],
   "source": [
    "# Filter rows where the language is English\n",
    "df_cleaned_en = df_cleaned[df_cleaned['language'] == 'en']\n",
    "\n",
    "# Drop the 'language' column since we don't need it anymore\n",
    "df_cleaned_en = df_cleaned_en.drop(columns=['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73f93d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b73f93d3",
    "outputId": "586462b7-53cb-46a5-9f9d-2517e070bdd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1324 abstracts after excluding non-English entries\n"
     ]
    }
   ],
   "source": [
    "# After manually checking the data, I found that some abstracts were labeled as English but\n",
    "# they contained the translated version in German as well. These cases can be handled in some way by extracting\n",
    "# only the English part, but let's keep things simple and just remove those entries.\n",
    "\n",
    "ids_to_remove = [\n",
    "    '0da4e154-6bbb-5a44-90be-18a8f032d716',\n",
    "    '37f017ad-6be1-e84e-81e0-664282061d63',\n",
    "    '47e9ddcd-3c80-5448-860a-55ac1623b72b',\n",
    "    '9be88a39-0572-8047-b3e4-2725d791876b',\n",
    "    'd6044191-6573-1848-ae7b-f215c922f201',\n",
    "    'b6e0b22c-c85a-224a-a1c6-39a7daebc058',\n",
    "    '006db203-8627-2f40-979e-5cd17aee5785'\n",
    "]\n",
    "\n",
    "df_cleaned_en = df_cleaned_en[~df_cleaned_en['id'].isin(ids_to_remove)]\n",
    "print('We have', df_cleaned_en.shape[0], 'abstracts after excluding non-English entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c33ba",
   "metadata": {
    "id": "802c33ba"
   },
   "source": [
    "<h1>Encoding of abstracts using TinyLlama-1.1B-Chat</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded406c",
   "metadata": {
    "id": "bded406c"
   },
   "source": [
    "Now we come to the part where we will use TinyLlama to encode our abstracts into vector representations. For this, ensure that you have the transformers library installed. The encodings will be stored and used later for clustering.\n",
    "\n",
    "Note that TinyLlama adopts an encoder-decoder architecture. However, we're only interested in the encoder component since it outputs the contextualized vector representation of the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cedf31",
   "metadata": {
    "id": "41cedf31"
   },
   "source": [
    "<h3 style=\"color:blue;\">Import the model and tokenizer from the transformers library</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gKI9e6robq8D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKI9e6robq8D",
    "outputId": "a65ae786-33d5-459d-bbfa-89c1222d1a7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5881ab7",
   "metadata": {
    "id": "c5881ab7"
   },
   "source": [
    "<h3 style=\"color:blue;\">Encode abstracts</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f66da5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "3f66da5b",
    "outputId": "76bc4961-69af-4d71-e34e-ed3f7b825e0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:50<00:00, 11.09s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_cleaned_en\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"01b59cbf-a13e-5546-9308-8c0e97e7fb48\",\n          \"00260961-8319-c84a-b84f-a83f557af45f\",\n          \"016ad184-a577-284f-a33f-21695132999a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Approach to validate the influences of uncertainties in manufacturing on using load-carrying structures\",\n          \"VNREAL: Virtual Network Resource Embedding Algorithms in the Framework ALEVIN\",\n          \"Determination of tomato quality attributes using portable NIR-sensors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstractText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"This paper gives an example of a new approach to display systematically uncertainties within the processchain to manufacture, to assemble and to use load-carrying structures to, eventually, control them in the future. By controlling uncertainties, safety margins between external loading and internal strength of a load carrying structure could be lowered, oversizing will be reduced, resources will be preserved, range of application will be widened and economic advantages will be achieved. In this work, the influences of uncertainties in manufacturing as well as assembling processes on the usage processes with respect to load distribution in a simple tripod is examined. If equal load distribution is desired, this equality highly depends on the quality of drilling holes for a leg connecting device. The holes vary in diameters, so the legs may be assembled differently. It will be shown exemplary, how deviations due to manufacturing may change the load distribution. Monte Carlo Simulation and real experiments on a simple tripod are conducted for validation.\",\n          \"Network virtualization is recognized as an enabling technology for the Future Internet that overcomes network ossification. However, it introduces a set of challenges. In any network virtualization environment, the problem of optimally mapping virtual resources to physical resources, known as virtual network embedding (VNE), is a critical challenge. Several algorithms attempting to solve this problem have been proposed in literature, so far. However, comparison of existing and new VNE algorithms is hard, as each algorithm focuses on different criteria. To that end, the VNREAL project introduces ALEVIN, a framework to compare different algorithms according to a set of metrics, easily incorporate new VNE algorithms, and evaluate these algorithms on a given scenario for arbitrary parameters.\",\n          \"As part of a research project a multidisciplinary approach of different research institutes is followed to investigate the possibility of using a commercially available miniaturized NIR-sensor for the determination of tomato fruit quality parameters in postharvest. Correlation of spectra and tomato reference values of firmness, dry matter and total soluble solids showed good prediction accuracy. Additionally the decline of firmness over storage time with respect to storage temperature of tomatoes could be modelled. Therefore, the decline of firmness as an indicator for shelf-life can be predicted using this portable NIR-Sensor.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_cleaned_en"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f4ead358-91cd-4981-9f39-bdebb7f3407f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000212c0-370f-df46-a901-1a8962645f6f</td>\n",
       "      <td>Measuring perceived depth in natural images an...</td>\n",
       "      <td>The perception of depth in images and video se...</td>\n",
       "      <td>[-0.08983136713504791, 0.9594758152961731, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00260961-8319-c84a-b84f-a83f557af45f</td>\n",
       "      <td>VNREAL: Virtual Network Resource Embedding Alg...</td>\n",
       "      <td>Network virtualization is recognized as an ena...</td>\n",
       "      <td>[0.19866445660591125, -0.5716489553451538, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0139e0f7-90c3-714e-8172-8be67ef9a66e</td>\n",
       "      <td>The heat flux and temperature distribution of ...</td>\n",
       "      <td>The thermal diffusion of nanostructured W fuzz...</td>\n",
       "      <td>[0.31982874870300293, 1.3281383514404297, 0.71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>013fa062-7f01-0647-bde9-baf4e13844bc</td>\n",
       "      <td>Characterization of Additively Produced RF-Str...</td>\n",
       "      <td>Usually, the printed circuit board industry ha...</td>\n",
       "      <td>[0.00956014171242714, 0.9851690530776978, 0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0146526d-6171-6244-85c4-94752d2cfde3</td>\n",
       "      <td>Stokes parameters in the unfolding of an optic...</td>\n",
       "      <td>Following our earlier work (F. Flossmann et al...</td>\n",
       "      <td>[0.3496668040752411, 0.44515469670295715, 0.35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4ead358-91cd-4981-9f39-bdebb7f3407f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f4ead358-91cd-4981-9f39-bdebb7f3407f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f4ead358-91cd-4981-9f39-bdebb7f3407f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-51bc640f-603e-4b55-8f67-a6eee7ab0b1e\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51bc640f-603e-4b55-8f67-a6eee7ab0b1e')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-51bc640f-603e-4b55-8f67-a6eee7ab0b1e button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   000212c0-370f-df46-a901-1a8962645f6f   \n",
       "6   00260961-8319-c84a-b84f-a83f557af45f   \n",
       "32  0139e0f7-90c3-714e-8172-8be67ef9a66e   \n",
       "35  013fa062-7f01-0647-bde9-baf4e13844bc   \n",
       "37  0146526d-6171-6244-85c4-94752d2cfde3   \n",
       "\n",
       "                                                title  \\\n",
       "0   Measuring perceived depth in natural images an...   \n",
       "6   VNREAL: Virtual Network Resource Embedding Alg...   \n",
       "32  The heat flux and temperature distribution of ...   \n",
       "35  Characterization of Additively Produced RF-Str...   \n",
       "37  Stokes parameters in the unfolding of an optic...   \n",
       "\n",
       "                                         abstractText  \\\n",
       "0   The perception of depth in images and video se...   \n",
       "6   Network virtualization is recognized as an ena...   \n",
       "32  The thermal diffusion of nanostructured W fuzz...   \n",
       "35  Usually, the printed circuit board industry ha...   \n",
       "37  Following our earlier work (F. Flossmann et al...   \n",
       "\n",
       "                                             encoding  \n",
       "0   [-0.08983136713504791, 0.9594758152961731, -0....  \n",
       "6   [0.19866445660591125, -0.5716489553451538, -0....  \n",
       "32  [0.31982874870300293, 1.3281383514404297, 0.71...  \n",
       "35  [0.00956014171242714, 0.9851690530776978, 0.64...  \n",
       "37  [0.3496668040752411, 0.44515469670295715, 0.35...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract keywords from the abstract text\n",
    "def encode_text(text):\n",
    "    # Tokenize the sentence\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    model_output = model(**encoded_input, output_hidden_states=True)\n",
    "\n",
    "    # Extract the embeddings from the model's output\n",
    "    last_hidden_state = model_output.hidden_states[-1][0]\n",
    "\n",
    "\n",
    "    # Since the encoder outputs a sequence on embeddings representing the contextual meaning of each token\n",
    "    # we need to calculate the average vector which represents the overall meaning of the entire sentence\n",
    "    text_embedding = torch.mean(last_hidden_state, dim=0).detach().numpy().tolist()\n",
    "\n",
    "    return text_embedding\n",
    "\n",
    "# Apply the function to the 'abstractText' column and create a new 'embedding' column\n",
    "df_cleaned_en['encoding'] = df_cleaned_en['abstractText'].progress_apply(encode_text)\n",
    "df_cleaned_en.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd16415",
   "metadata": {
    "id": "2dd16415"
   },
   "source": [
    "<h1> Keywords extraction using KeyBERT</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3af3486",
   "metadata": {
    "id": "f3af3486"
   },
   "source": [
    "Now we want to use KeyBERT to extract the most relavent keywords from each abstract. So why this step is important?\n",
    "Extracting keywords with KeyBERT is crucial for interpreting the clusters later on. Since we are working in an unsupervised setting and we lack predefined labels, keywords help us understand the main topics of the clusters. We can identify the topic by analyzing the most frequent keywords within a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e0e043",
   "metadata": {
    "id": "56e0e043"
   },
   "source": [
    "<h3 style=\"color:blue;\">Import the model and create an instance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e21640",
   "metadata": {
    "id": "93e21640"
   },
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f9a90",
   "metadata": {
    "id": "f99f9a90"
   },
   "source": [
    "<h3 style=\"color:blue;\">Extract keywords from the abstracts</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face0b57",
   "metadata": {
    "id": "face0b57",
    "outputId": "a7281176-d1d1-4c72-ced6-acd16cf5b3b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1324/1324 [05:00<00:00,  4.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>encoding</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000212c0-370f-df46-a901-1a8962645f6f</td>\n",
       "      <td>Measuring perceived depth in natural images an...</td>\n",
       "      <td>The perception of depth in images and video se...</td>\n",
       "      <td>[-0.3123984634876251, 0.2054155468940735, 0.27...</td>\n",
       "      <td>[binocular, depth, perception, perspective, blur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00260961-8319-c84a-b84f-a83f557af45f</td>\n",
       "      <td>VNREAL: Virtual Network Resource Embedding Alg...</td>\n",
       "      <td>Network virtualization is recognized as an ena...</td>\n",
       "      <td>[-0.47408998012542725, 0.15451061725616455, 0....</td>\n",
       "      <td>[virtualization, vnreal, vne, virtual, network]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0139e0f7-90c3-714e-8172-8be67ef9a66e</td>\n",
       "      <td>The heat flux and temperature distribution of ...</td>\n",
       "      <td>The thermal diffusion of nanostructured W fuzz...</td>\n",
       "      <td>[-0.31249314546585083, -0.014937079511582851, ...</td>\n",
       "      <td>[irradiations, fusion, fuzz, thermal, nanostru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>013fa062-7f01-0647-bde9-baf4e13844bc</td>\n",
       "      <td>Characterization of Additively Produced RF-Str...</td>\n",
       "      <td>Usually, the printed circuit board industry ha...</td>\n",
       "      <td>[-0.2447933405637741, 0.0641787126660347, 0.36...</td>\n",
       "      <td>[inkjet, impedance, rf, ghz, substrates]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0146526d-6171-6244-85c4-94752d2cfde3</td>\n",
       "      <td>Stokes parameters in the unfolding of an optic...</td>\n",
       "      <td>Following our earlier work (F. Flossmann et al...</td>\n",
       "      <td>[-0.26581481099128723, -0.08620522916316986, 0...</td>\n",
       "      <td>[polarization, birefringent, vortices, stokes,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  \\\n",
       "0   000212c0-370f-df46-a901-1a8962645f6f   \n",
       "6   00260961-8319-c84a-b84f-a83f557af45f   \n",
       "32  0139e0f7-90c3-714e-8172-8be67ef9a66e   \n",
       "35  013fa062-7f01-0647-bde9-baf4e13844bc   \n",
       "37  0146526d-6171-6244-85c4-94752d2cfde3   \n",
       "\n",
       "                                                title  \\\n",
       "0   Measuring perceived depth in natural images an...   \n",
       "6   VNREAL: Virtual Network Resource Embedding Alg...   \n",
       "32  The heat flux and temperature distribution of ...   \n",
       "35  Characterization of Additively Produced RF-Str...   \n",
       "37  Stokes parameters in the unfolding of an optic...   \n",
       "\n",
       "                                         abstractText  \\\n",
       "0   The perception of depth in images and video se...   \n",
       "6   Network virtualization is recognized as an ena...   \n",
       "32  The thermal diffusion of nanostructured W fuzz...   \n",
       "35  Usually, the printed circuit board industry ha...   \n",
       "37  Following our earlier work (F. Flossmann et al...   \n",
       "\n",
       "                                             encoding  \\\n",
       "0   [-0.3123984634876251, 0.2054155468940735, 0.27...   \n",
       "6   [-0.47408998012542725, 0.15451061725616455, 0....   \n",
       "32  [-0.31249314546585083, -0.014937079511582851, ...   \n",
       "35  [-0.2447933405637741, 0.0641787126660347, 0.36...   \n",
       "37  [-0.26581481099128723, -0.08620522916316986, 0...   \n",
       "\n",
       "                                             keywords  \n",
       "0   [binocular, depth, perception, perspective, blur]  \n",
       "6     [virtualization, vnreal, vne, virtual, network]  \n",
       "32  [irradiations, fusion, fuzz, thermal, nanostru...  \n",
       "35           [inkjet, impedance, rf, ghz, substrates]  \n",
       "37  [polarization, birefringent, vortices, stokes,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract keywords from the abstract text\n",
    "def extract_keywords_from_text(text):\n",
    "    keywords = kw_model.extract_keywords(text)\n",
    "    return [keyword[0] for keyword in keywords]\n",
    "\n",
    "# Apply the function to the 'abstractText' column and create a new 'keywords' column\n",
    "df_cleaned_en['keywords'] = df_cleaned_en['abstractText'].progress_apply(extract_keywords_from_text)\n",
    "df_cleaned_en.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec4851",
   "metadata": {
    "id": "7fec4851"
   },
   "source": [
    "<h1>Export the final processed data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7faf1",
   "metadata": {
    "id": "06a7faf1"
   },
   "outputs": [],
   "source": [
    "# Convert to JSON\n",
    "json_data = df_cleaned_en.to_json(orient='records', lines=True)\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open('output/abstracts_processed.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07ec6c",
   "metadata": {
    "id": "5e07ec6c"
   },
   "source": [
    "We've processed the abstracts, encoded them, and extracted keywords. Now, let's head to the next notebook for the clustering stage."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
